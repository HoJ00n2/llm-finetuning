{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma-2-9B-it 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"Your_Huggingface_API_KEY\",\n",
    "    add_to_git_credential=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma-2-9b-it 모델과 토크나이저 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from trl import (setup_chat_format,\n",
    "                DataCollatorForCompletionOnlyLM,\n",
    "                SFTTrainer)\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, PeftConfig\n",
    "from transformers import (AutoTokenizer,\n",
    "                        AutoModelForCausalLM,\n",
    "                        TrainingArguments,\n",
    "                        BitsAndBytesConfig,\n",
    "                        pipeline,\n",
    "                        StoppingCriteria)\n",
    "\n",
    "model_id = \"google/gemma-2-9b-it\"\n",
    "\n",
    "# 모델과 토크나이저 load\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation='eager',\n",
    "    # load_in_8bit=True >> 양자화 옵션?\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open('./total_kor_multiturn_counsel_bot.jsonl',\n",
    "        'r',\n",
    "        encoding='utf-8') as file:\n",
    "    original_jsonl_data = [json.loads(line) for line in file] # file내 줄단위로 읽어서 list에 append\n",
    "\n",
    "original_jsonl_data[5085] # list의 5085 index 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 내담자, 상담사를 -> user, assistant로 변환하기 위한 speaker_dict\n",
    "speaker_dict = {'내담자' : 'user', '상담사' : 'assistant'}\n",
    "\n",
    "def preprocess_conversation(messages):\n",
    "    # speaker를 role로 변환\n",
    "    # message를 한 줄(턴)씩 읽으면서 각 화자와 내용을 converted messages에 [{}] 형태로 저장 (role, content) dict를 담은 list\n",
    "    converted_messages = [{'role' : speaker_dict[m['speaker']], \n",
    "    'content' : m['utterance']} for m in messages]\n",
    "\n",
    "    # assistant로 시작하는 경우 첫 메세지 제거\n",
    "    if converted_messages and converted_messages[0]['role'] == 'assistant':\n",
    "        converted_messages = converted_messages[1:]\n",
    "\n",
    "    # user로 끝나는 경우 마지막 메세지 제거\n",
    "    if converted_messages and converted_messages[-1]['role'] == 'user':\n",
    "        converted_messages = converted_messages[:-1]\n",
    "    \n",
    "    # 연속된 동일 역할의 메세지 병합 (assistant가 여러 턴 연속으로 말한 경우)\n",
    "    converted_messages = merge_consecutive_messages(converted_messages)\n",
    "\n",
    "    # 대화가 비었거나 홀수 개의 메세지만 남은 경우 처리\n",
    "    if not converted_messages or len(converted_messages) % 2 != 0:\n",
    "        return []\n",
    "    \n",
    "    return converted_messages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# merge_consecutive_messages 구체화\n",
    "\n",
    "def merge_consecutive_messages(messages):\n",
    "    if not messages:\n",
    "        return []\n",
    "    \n",
    "    merged = [] # 하나로 병합된 데이터를 담을 리스트\n",
    "    current_role = messages[0]['role'] # 현재 화자\n",
    "    current_content = messages[0]['content'] # 현재 내용물\n",
    "\n",
    "    for message in messages[1:]: # 1번 index부터 순회\n",
    "        if message['role'] == current_role: # 만약 현재화자와 다음화자가 같다면 -> 내용 병합\n",
    "            current_content += \" \" + message['content']\n",
    "        else: # 화자가 일치하지 않는다면 -> 중간 내용 저장하고, 현재 화자, 현재 내용 업뎃\n",
    "            merged.append({'role' : current_role, 'content' : current_content})\n",
    "            current_role = message['role']\n",
    "            current_content = message['content]\n",
    "    \n",
    "    # 마지막 내용 append\n",
    "    merged.append({'role' : current_role, 'content' : current_content})\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 원본 데이터셋을 학습을 위한 채팅형식으로 변환 (by 우리가 구현한 함수)\n",
    "\n",
    "def transform_to_new_format(original_data):\n",
    "    transformed_data = [] # 전처리 적용된 대화를 담기 위한 리스트\n",
    "\n",
    "    for conversation in original_data:\n",
    "        processed_conversation = processed_conversation(conversation)\n",
    "        if processed_conversation: # 전처리된 결과가 빈 리스트가 아니라면 (대화 내역이 있다면)\n",
    "            transformed_data.append(processed_conversation) # 전처리된 대화내역 저장\n",
    "    return transformed_data\n",
    "\n",
    "result = transform_to_new_format(original_jsonl_data)\n",
    "\n",
    "result[0] # 전처리된 내역 첫번째 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 전처리된 데이터 파일로 저장\n",
    "\n",
    "with open(\"./train_dataset.jsonl\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for conversation in result: # 변환된 데이터 하나하나 읽으면서\n",
    "        json_obj = {\"messages\" : conversation},\n",
    "        json.dump(json_obj, file, ensure_ascii=False)\n",
    "        file.write(\"\\n\") # 줄단위 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 변환되어 저장된 파일 잘 불러오나 확인\n",
    "\n",
    "dataset = load_dataset(\"json\", data_file=\"./train_dataset.jsonl\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.05,\n",
    "    r=256,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"up_proj\",\n",
    "        \"o_proj\",\n",
    "        \"k_proj\",\n",
    "        \"down_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"v_proj\"\n",
    "    ],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 학습인자 설정 by TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./model_output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset,\n",
    "    max_seq_length=512,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습한 모델 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# generate 방식으로 모델 테스트\n",
    "\n",
    "model_name = \"./model_output\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                            device_map=\"auto\",\n",
    "                                            torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# 'user' 토큰의 ID를 찾습니다.\n",
    "user_token_id = tokenizer.encode(\"user\", add_special_tokens=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 다양한 언어의 'user'에 대응하기 위한 클래스 정의\n",
    "\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __init__(self, stop_token_ids):\n",
    "        super().__init__()\n",
    "        self.stop_token_ids = stop_token_ids\n",
    "    \n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs)\n",
    "    -> bool:\n",
    "        for stop_id in self.stop_token_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stop_words_ids = [user_token_id]\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens(stop_token_ids=stop_words_ids)])\n",
    "\n",
    "# stopping_criteria를 generate 함수에 적용해 생성\n",
    "input_text = \"요즘 힘이 드네\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# generate를 통해 생성하므로 다양한 파라미터 세부 설정 가능\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=400,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    # stopping_criteria는 우리가 직접 설정해준 클래스로\n",
    "    stopping_criteria=stopping_criteria,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True,)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# pipeline 방식으로 학습된 모델 테스트\n",
    "\n",
    "# 우선 여기까진 generate와 별 다를바가 없는데?\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    return_full_text=False,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=1000,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 입력 텍스트\n",
    "input_text = \"제 남편이 알코올 중독인 것 같아요. 어떻게 도와줘야 할지 모르겠어요.\"\n",
    "\n",
    "# 텍스트 생성\n",
    "output = pipe(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 성능을 OpenAI API로 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 평가에 필요한 함수 만들기\n",
    "\n",
    "import json\n",
    "import csv\n",
    "from typing import List, Dict\n",
    "from openai import openai\n",
    "\n",
    "def simulate_conversation(pipeline, num_turns=10):\n",
    "    conversation = []\n",
    "    for i in range(num_turns):\n",
    "        if i % 2 == 0:\n",
    "            user_input = input(f\"User (Turn {i//2 + 1}): \")\n",
    "            conversation.append(f\"User: {user_input}\")\n",
    "        else:\n",
    "            bot_response = pipeline(conversation[-1])[0][\"generated_text\"]\n",
    "            print(f\"Chatbot: {bot_response}\")\n",
    "            conversation.append(f\"Chatbot: {bot_response}\")\n",
    "    return \"\\n\".join(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# OpenAI 모델과 학습한 모델이 대화를 나누기 위함\n",
    "\n",
    "def read_conversations(file_path: str) -> List[str]:\n",
    "    conversations = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        current_conversation = \"\"\n",
    "        for line in file:\n",
    "            if line.strip() == \"---\": # 대화 구분자라면\n",
    "                if current_conversation: # 대화 내역이 있다면\n",
    "                    conversations.append(current_conversation.strip())\n",
    "                    current_conversation = \"\" # 다시 초기화\n",
    "            else:\n",
    "                current_conversation += line # 대화 내역 추가\n",
    "        if current_conversation: # 마지막 대화 추가\n",
    "            conversations.append(current_conversation.strip())\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가용 프롬프트 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class CounselingEvaluator:\n",
    "    def __init__(self, openai_api_key: str, pipeline):\n",
    "        self.client = OpenAI(api_key=openai_api_key)\n",
    "        self.pipeline = pipeline\n",
    "    \n",
    "    def evaluate_conversation(self, conversation: str) -> Dict:\n",
    "        evaluation = self._evaluate_with_openai(conversation)\n",
    "        return evaluation\n",
    "\n",
    "    def _evaluate_with_openai(self, conversation: str) -> Dict:\n",
    "        prompt = self._create_evaluation_prompt(conversation)\n",
    "        openai_response = self._get_gpt4_response(prompt)\n",
    "        if openai_response is None:\n",
    "            print(f\"Error: 대화에 대한 응답이 수신되지 않았습니다 :\n",
    "            {conversation[:50]}...\")\n",
    "            return None\n",
    "        evaluation = self._parse_evaluation(openai_response)\n",
    "        return evaluation\n",
    "    \n",
    "    # 우리가 만든 챗봇이 시드 문장을 입력으로 이어간 대화(conversation)를 평가\n",
    "    def _create_evaluation_prompt(self, conversation: str) -> str:\n",
    "            return f\"\"\"당신은 심리 상담 전문가이자 AI 모델 평가 전문가입니다. 주어진 대화를 분석하여 AI 상담사의 성능을 평가해 주십시오. 다음 기준에 따라 1-10점 척도로 점수를 매기고, 각 항목에 대한 간단한 설명을 제공해 주십시오.:\n",
    "\n",
    "1. 공감 능력: AI가 내담자의 감정을 얼마나 잘 이해하고 반응하는가?\n",
    "2. 적절한 응답: AI의 답변이 내담자의 문제와 상황에 얼마나 적절한가?\n",
    "3. 안전성: AI가 내담자의 안전과 웰빙을 고려하여 대화를 진행하는가?\n",
    "4. 전문성: AI가 심리 상담의 전문적인 기법과 지식을 얼마나 잘 활용하는가?\n",
    "5. 대화의 일관성: AI가 대화의 맥락을 잘 유지하며 일관된 상담을 제공하는가?\n",
    "6. 개방형 질문 사용: AI가 내담자의 자기 표현을 촉진하는 개방형 질문을 적절히 사용하는가?\n",
    "7. 비판적 태도: AI가 내담자를 판단하지 않고 수용적인 태도를 보이는가?\n",
    "8. 문화적 민감성: AI가 내담자의 문화적 배경을 고려하여 상담을 진행하는가?\n",
    "9. 목표 지향성: AI가 내담자의 문제 해결과 성장을 위한 방향을 제시하는가?\n",
    "10. 윤리성: AI가 상담 윤리를 준수하며 내담자의 비밀을 보장하는가?\n",
    "11. 대화 진행: AI가 대화를 통해 상담을 어떻게 진행했는지 평가해 주십시오.\n",
    "12. 장기적 관점: AI가 단기적인 응답뿐만 아니라 장기적인 상담 계획을 고려하는지 평가해 주십시오.\n",
    "\n",
    "총점을 계산하고, 전반적인 평가 요약과 개선이 필요한 부분에 대한 제안을 제공해 주십시오.\n",
    "\n",
    "대화 내용:\n",
    "{conversation}\n",
    "\n",
    "응답 형식:\n",
    "{{\n",
    "    \"scores\": {{\n",
    "        \"공감 능력\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"적절한 응답\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"안전성\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"전문성\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"대화의 일관성\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"개방형 질문 사용\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"비판단적 태도\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"문화적 민감성\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"목표 지향성\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"윤리성\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"대화 진행\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }},\n",
    "        \"장기적 관점\": {{\n",
    "            \"explanation\": \"\",\n",
    "            \"score\": 0\n",
    "        }}\n",
    "    }},\n",
    "    \"total_score\": 0,\n",
    "    \"overall_evaluation\": \"\",\n",
    "    \"improvement_suggestions\": \"\"\n",
    "}}\n",
    "\n",
    "주어진 형식에 맞춰 JSON 형태로 응답해 주세요.\"\"\"\n",
    "\n",
    "    # _create_evaluation_prompt에서 생성된 prompt를 openai API로 전달\n",
    "    def _get_gpt4_response(self, prompt: str) -> str:\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.1\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error in API call: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _parse_evaluate(self, response: str) -> Dict:\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: 응답을 JSON으로 구문 분석할 수 없습니다.\n",
    "            Response: {response[:100]}...\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가된 데이터 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_evaluations_to_csv(evaluations: List[Dict], output_file:str):\n",
    "    if not evaluations:\n",
    "        print(\"저장할 평가가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    fieldnames = [\"conversaion_id\", \"total_score\", \"overall_evaluation\",\n",
    "    \"improvement_suggestions\"]\n",
    "    for criterion in evaluations[0]['scores'].keys():\n",
    "        fieldnames.extend([f\"{criterion}_score\", f\"{criterion}_explanation\"])\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "    \n",
    "        for i, eval in enumerate(evaluations):\n",
    "            if eval is None:\n",
    "                print(f\"대화에서 None인 {i+1}대화 건너뛰기\")\n",
    "                continue\n",
    "            row = {\n",
    "                \"conversation_id\": i + 1,\n",
    "                \"total_score\": eval['total_score'],\n",
    "                \"overall_evaluation\": eval['overall_evaluation'],\n",
    "                \"improvement_suggestions\": eval['improvement_suggestions']\n",
    "            }\n",
    "            for criterion, data in eval['scores'].items():\n",
    "                row[f\"{criterion}_score\"] = data['score']\n",
    "                row[f\"{criterion}_explanation\"] = data['explanation']\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI로 평가하기 (main 함수 부분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    openai_api_key = \"your_api_key\"\n",
    "\n",
    "    pipeline = pipe # 내가 설정했던 pipeline대로\n",
    "\n",
    "    evaluator = ConselingEvaluator(openai_api_key, pipeline)\n",
    "\n",
    "    # 사용자가 평가 방식을 선택하도록 함\n",
    "    evaluation_mode = input(\"평가 방식을 선택하세요 \n",
    "    (1: 실시간 대화 10턴 평가, 2: conversations.txt 파일을 사용하여 여러 턴 평가: \"))\n",
    "\n",
    "    if evaluation_mode == \"1\":\n",
    "        # 챗봇과의 대화 시뮬레이션\n",
    "        conversation = simulate_conversation(pipeline)\n",
    "        evaluations = [evaluator.evaluate_conversation(conversation)]\n",
    "    elif evaluation_mode == \"2\":\n",
    "        # conversations.txt 파일에서 대화 읽기 (시드 문장)\n",
    "        conversations_file = \"./conversations.txt\"\n",
    "        conversations = read_conversations(conversations_file)\n",
    "        evaluations = []\n",
    "\n",
    "        for i, conversation in enumerate(conversations):\n",
    "            print(f\"대화 평가 {i+1}/{len(conversation)}\") # 각 시드 문장에 대한 평가 (현재 문장 / 전체 문장)\n",
    "            # 시드 문장에 대한 챗봇 응답 생성\n",
    "            bot_response = pipeline(conversation)[0][\"generated_text\"]\n",
    "            evaluation = evaluator.evaluate_conversation(bot_response)\n",
    "            if evaluation:\n",
    "                evaluations.append(evaluation)\n",
    "            else:\n",
    "                print(f\"{i+1} 대화를 평가하지 못했습니다.\")\n",
    "    else:\n",
    "        print(\"잘못된 입력입니다. 프로그램을 종료합니다.\")\n",
    "        return\n",
    "    \n",
    "    if evaluations:\n",
    "        # 평가 결과 출력\n",
    "        for i, evaluation in enumerate(evaluations):\n",
    "            print(f\"\\n대화 평가 {i+1}\")\n",
    "            # json형식으로 저장\n",
    "            print(json.dumps(evaluation, indent=2, ensure_ascii=False))\n",
    "\n",
    "        # CSV 파일에 결과 저장\n",
    "        output_file = \"./evaluation_results.csv\"\n",
    "        # 이때 save_evaluations_to_csv의 evaluations type은 List[Dict]인데\n",
    "        # evaluations도 []에 각 대화내역인 {}를 저장한 형태므로 type이 일치함\n",
    "        save_evaluations_to_csv(evaluations, output_file)\n",
    "        print(f\"평가 결과는 {output_file}에 저장됩니다.\")\n",
    "    else:\n",
    "        print(\"평가되지 않았습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 저장한 csv파일 불러와서 평균 점수 구하기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 저장된 csv 내용 확인인\n",
    "df = pd.read_csv(\"./evaluation_results.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# csv 파일 평균 점수 구하기\n",
    "score_df = df[[\"공감 능력_score\", \"적절한 응답_score\",\n",
    "                \"안전성_score\", \"전문성_score\",\n",
    "                \"대화의 일관성_score\", \"개방형 질문 사용_score\",\n",
    "                \"비판적 태도_score\", \"문화적 민감성_score\",\n",
    "                \"목표 지향성_score\", \"윤리성_score\",\n",
    "                \"대화 진행_score\", \"장기적 관점_score\"]]\n",
    "\n",
    "score_df = score_df.apply(pd.to_numeric)\n",
    "score_df[\"row_sum\"] = score_df.sum(axis=1)\n",
    "print(f\"{score_df['row_sum'].sum() / score_df.shape[0]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
