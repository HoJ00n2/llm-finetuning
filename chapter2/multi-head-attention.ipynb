{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 멀티헤드 어텐션과 피드포워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# self-attention에서 만든 Head class를 가져옴\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)]) # ModuleList의 기능?\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return torch.cat([head(inputs) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 피드포워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_tensor):\n",
    "        return self.layer(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Attention, FeedForward 기능 모두 하나로 합쳐 돌아가는 트랜스포머 기본구조\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "        self.attention = MultiheadAttention(n_heads, head_size)\n",
    "        self.feedforward = FeedForward(n_embed)\n",
    "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
    "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # 여기서의 입력의 shape는 n_embed 뿐인가? (왜 self.layer_norm1에 input_tensor 통째로 넣지?)\n",
    "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
    "        input_tensor = input_tensor + self.feedforward(self.layer_norm2(input_tensor))\n",
    "        return input_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토크나이저 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# 저장 경로\n",
    "SAVE_DIR = \"/content\"\n",
    "\n",
    "# 디렉터리가 없다면 생성\n",
    "os.mkdir(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizers = Whitespace()\n",
    "\n",
    "# 트레이너 준비 (vocab_size 지정)\n",
    "trainer = BpeTrainer(\n",
    "    special_tokens=[\"<unk>\", \"<s>\", \"</s>\", \"<pad>\"],\n",
    "    vocab_size=VOCAB_SIZE\n",
    ")\n",
    "\n",
    "# 토크나이저 학습\n",
    "def batch_iteration(batch_size=1000):\n",
    "    for i in range(0, len(dataset[\"train\"]), batch_size):\n",
    "        yield dataset[\"train\"][i : i + batch_size][\"document\"]\n",
    "\n",
    "tokenizer.train_from_iterator(batch_iteration(), trainer=trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 토크나이저를 JSON 파일로 저장\n",
    "tokenizer_path = os.path.join(SAVE_DIR, \"tokenizer.json\")\n",
    "tokenizer.save(tokenizer_path)\n",
    "\n",
    "# 토크나이저를 Hugging Face 형식으로 변환\n",
    "huggingface_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    unk_token=\"<unk>\",\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    pad_token=\"<pad>\"\n",
    ")\n",
    "\n",
    "# Hugging Face 형식의 토크나이저 저장\n",
    "huggingface_path = os.path.join(SAVE_DIR, \"huggingface_tokenizer\")\n",
    "huggingface_tokenizer.save_pretrained(huggingface_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Hugging Face 형식의 토크나이저 로드\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_path)\n",
    "\n",
    "# 어휘 크기 확인\n",
    "print(f\"Vocabulary size : {len(tokenizer.get_vocab())}\")\n",
    "\n",
    "# 테스트\n",
    "test_texts = [\"안녕하세요\", \"자연어 처리는 매우 흥미로운 분야입니다\", \"인공지능과\n",
    "기계학습의 발전이 놀랍습니다\"]\n",
    "for text in test_texts:\n",
    "    encoded = tokenizer.encode(text) # 텍스트 토크나이징하여 숫자로 변환\n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"Encoded: {encoded}\")\n",
    "    print(f\"Decoded: {tokenizer.decode(encoded)}\")\n",
    "    print(f\"Tokens: {tokenizer.convert_ids_to_tokens(encoded)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
